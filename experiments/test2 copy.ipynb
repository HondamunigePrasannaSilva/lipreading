{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype of lipreading pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "# model file, encoder, decoder and seqtoseq\n",
    "from model_temp import *\n",
    "# utils file\n",
    "from utils import *\n",
    "# Get landmark using vocadataset.py\n",
    "from data.vocaset import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get landmark from vocadaset class\n",
    "#trainset = vocadataset(\"train\", landmark=True)\n",
    "trainset = vocadataset(\"train\", landmark=True, mouthOnly=True)\n",
    "#landmark, labels = trainset[0]\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=20, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "#landmarks, len_landmark, label, len_label = next(iter(trainloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = create_vocabulary(blank=\"@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from characters to indices\n",
    "char_to_index = {char: index for index, char in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the sequence and target to indices\n",
    "#sequence_indices = [char_to_index[char] for char in sequence]\n",
    "\n",
    "label_t = char_to_index_batch(label, vocabulary)\n",
    "\n",
    "#target_indices = [char_to_index[char] for char in labels]\n",
    "#target_tensor = torch.tensor(target_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 36*3\n",
    "INPUT_DIM = 36*3\n",
    "HID_DIM = 64\n",
    "output_dim = len(vocabulary)\n",
    "\n",
    "model = only_Decoder2(INPUT_DIM, HID_DIM, 2, len(vocabulary)).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CTC loss function\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i in range(landmarks.shape[0]):\n",
    "        landmarks[i] = landmarks[i].to(device) \n",
    "        label_t[i] = label_t[i].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        target_tensor = label_t[i]\n",
    "\n",
    "        \n",
    "\n",
    "        reshaped_landmark = torch.reshape(landmarks[i], (landmarks[i].shape[0], landmarks[i].shape[1]*landmarks[i].shape[2]))\n",
    "        reshaped_landmark = reshaped_landmark.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "        len_landmark[i] = len_landmark[i].to(device) \n",
    "        output = model(reshaped_landmark[None, : , :], len_landmark[i][None])\n",
    "        output = output.permute(1,0,2)\n",
    "        input_lengths = torch.full((1,), output.size(0), dtype=torch.long)\n",
    "        target_lengths = torch.full((target_tensor.size(0),), target_tensor.size(0), dtype=torch.int32)\n",
    "        \n",
    "        loss = ctc_loss(torch.nn.functional.log_softmax(output, dim=2), target_tensor, input_lengths, target_lengths[0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        e = torch.argmax(output, dim=2).squeeze(1)\n",
    "        output_sequence = ''.join([vocabulary[index] for index in e])\n",
    "        #print(output_sequence)\n",
    "        if(epoch + 1) % 100 == 0:\n",
    "            f = open(\"prova_.txt\", \"a\")\n",
    "            f.write(label[i]+\"\\n\")\n",
    "            f.write(output_sequence+\"\\n\")\n",
    "            f.close() \n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "        #e = torch.argmax(output, dim=2).squeeze(1)\n",
    "        #output_sequence = ''.join([vocabulary[index] for index in e])\n",
    "        #print(output_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CTC loss function\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 500\n",
    "for landmarks, len_landmark, label, len_label in trainloader:\n",
    "    #landmarks, len_landmark, label, len_label = next(iter(trainloader))\n",
    "    label_t = char_to_index_batch(label, vocabulary)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for i in range(landmarks.shape[0]):\n",
    "            landmarks[i] = landmarks[i].to(device) \n",
    "            label_t[i] = label_t[i].to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            #remove padding from dataloader\n",
    "            nw = landmarks[i][:len_landmark[i], :, :].clone().detach().requires_grad_(True)\n",
    "            nw_l = label_t[i][:len_label[i]].clone().detach()\n",
    "            \n",
    "            target_tensor = nw_l\n",
    "            reshaped_landmark = torch.reshape(nw, (nw.shape[0], nw.shape[1]*nw.shape[2]))\n",
    "            reshaped_landmark = reshaped_landmark.to(device)\n",
    "            target_tensor = target_tensor.to(device)\n",
    "            len_landmark[i] = len_landmark[i].to(device) \n",
    "            output = model(reshaped_landmark[None, : , :], len_landmark[i][None])\n",
    "            output = output.permute(1,0,2)\n",
    "            input_lengths = torch.full((1,), output.size(0), dtype=torch.long)\n",
    "            target_lengths = torch.full((target_tensor.size(0),), target_tensor.size(0), dtype=torch.int32)\n",
    "            \n",
    "            loss = ctc_loss(torch.nn.functional.log_softmax(output, dim=2), target_tensor, input_lengths, target_lengths[0])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            e = torch.argmax(output, dim=2).squeeze(1)\n",
    "            output_sequence = ''.join([vocabulary[index] for index in e])\n",
    "            #print(output_sequence)\n",
    "            \"\"\"if(epoch + 1) % 100 == 0:\n",
    "                f = open(\"prova_.txt\", \"a\")\n",
    "                f.write(str(nw_l.tolist())+\"\\n\")\n",
    "                f.write(output_sequence+\"\\n\")\n",
    "                f.close() \n",
    "        \"\"\"\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "            #e = torch.argmax(output, dim=2).squeeze(1)\n",
    "            #output_sequence = ''.join([vocabulary[index] for index in e])\n",
    "            #print(output_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CTC loss function\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "###########\n",
    "\n",
    "#trainset = vocadataset(\"train\", landmark=True)\n",
    "trainset_ = vocadataset(\"train\", landmark=True, mouthOnly=True)\n",
    "#landmark, labels = trainset[0]\n",
    "trainset_ = trainset_.to(device)\n",
    "trainloader_ = DataLoader(trainset_, batch_size=1, collate_fn=collate_fn, num_workers=8)\n",
    "\n",
    "\n",
    "###########Ã "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 36*3\n",
    "INPUT_DIM = 36*3\n",
    "HID_DIM = 64\n",
    "output_dim = len(vocabulary)\n",
    "\n",
    "model = only_Decoder2(INPUT_DIM, HID_DIM, 2, len(vocabulary)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(trainset_[0][0].shape[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CTC loss function\n",
    "ctc_loss = nn.CTCLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "###########\n",
    "trainset_ = vocadataset(\"train\", landmark=True, mouthOnly=True)\n",
    "\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10000\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    for i  in range(10):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        landmarks = trainset_[i][0].to(device) \n",
    "        \n",
    "        label_t = char_to_index_batch(trainset_[i][1], vocabulary)\n",
    "        label_t = label_t.to(device)\n",
    "        target_tensor = label_t\n",
    "        reshaped_landmark = torch.reshape(landmarks, (landmarks.shape[0], landmarks.shape[1]*landmarks.shape[2]))\n",
    "        reshaped_landmark = reshaped_landmark.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "        len_landmark = torch.tensor(landmarks.shape[0]).to(device) \n",
    "        output = model(reshaped_landmark[None, : , :], len_landmark[None])\n",
    "        output = output.permute(1,0,2)\n",
    "        input_lengths = torch.full((1,), output.size(0), dtype=torch.long)\n",
    "        target_lengths = torch.full((target_tensor.size(0),), target_tensor.size(0), dtype=torch.int32)\n",
    "        \n",
    "        loss = ctc_loss(torch.nn.functional.log_softmax(output, dim=2), target_tensor.squeeze(), input_lengths, target_lengths[0][None])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        e = torch.argmax(output, dim=2).squeeze(1)\n",
    "        output_sequence = ''.join([vocabulary[index] for index in e])\n",
    "        #print(output_sequence)\n",
    "        if(epoch + 1) % 100 == 0:\n",
    "            f = open(\"prova_.txt\", \"a\")\n",
    "            f.write(label[i]+\"\\n\")\n",
    "            f.write(output_sequence+\"\\n\")\n",
    "            f.close() \n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}\")\n",
    "        #e = torch.argmax(output, dim=2).squeeze(1)\n",
    "        #output_sequence = ''.join([vocabulary[index] for index in e])\n",
    "        #print(output_sequence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "valset = vocadataset(\"val\", landmark=True, mouthOnly=True)\n",
    "#landmark, labels = trainset[0]\n",
    "\n",
    "valloader = DataLoader(valset, batch_size=1, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.load_state_dict(torch.load(\"/home/prasanna/Documents/UNIFI/Computer Graphics/LipReading/lipreading/models/model_f__5500_7.pt\"))\n",
    "model.eval()\n",
    "\n",
    "real_sentences = []\n",
    "pred_sentences = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for landmarks, len_landmark, label, len_label in valloader:\n",
    "\n",
    "        # reshape the batch from [batch_size, frame_size, num_landmark, 3] to [batch_size, frame_size, num_landmark * 3] \n",
    "        landmarks = torch.reshape(landmarks, (landmarks.shape[0], landmarks.shape[1], landmarks.shape[2]*landmarks.shape[3]))\n",
    "        \n",
    "        #variable to recover later the target sequences\n",
    "        label_list = label\n",
    "\n",
    "        # label char to index\n",
    "        label = char_to_index_batch(label, vocabulary)\n",
    "\n",
    "        # move data to GPU!\n",
    "        landmarks = landmarks.to(device)\n",
    "        len_landmark = len_landmark.to(device)\n",
    "        label = label.to(device)\n",
    "        len_label = len_label.to(device)\n",
    "\n",
    "        output = model(landmarks, len_landmark)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        # scrittura nel file del outuput e della frase originale\n",
    "\n",
    "        real_sentences, pred_sentences = write_results(len_label, label_list, output.detach(), valloader.batch_size, vocabulary, real_sentences, pred_sentences)\n",
    "\n",
    "    pred_sentences = list(map(lambda x:process_string(x),pred_sentences))\n",
    "    save_results(f\"./results/validation.txt\", real_sentences, pred_sentences, overwrite=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge import Rouge\n",
    "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "\n",
    "\n",
    "def calculate_exact_match(model_output, ground_truth):\n",
    "    return int(model_output == ground_truth)\n",
    "\n",
    "\n",
    "def calculate_word_error_rate(model_output, ground_truth):\n",
    "    model_words = model_output.split()\n",
    "    ground_truth_words = ground_truth.split()\n",
    "    len_model = len(model_words)\n",
    "    len_gt = len(ground_truth_words)\n",
    "\n",
    "    dp = [[0] * (len_gt + 1) for _ in range(len_model + 1)]\n",
    "\n",
    "    for i in range(len_model + 1):\n",
    "        dp[i][0] = i\n",
    "\n",
    "    for j in range(len_gt + 1):\n",
    "        dp[0][j] = j\n",
    "\n",
    "    for i in range(1, len_model + 1):\n",
    "        for j in range(1, len_gt + 1):\n",
    "            if model_words[i - 1] == ground_truth_words[j - 1]:\n",
    "                dp[i][j] = dp[i - 1][j - 1]\n",
    "            else:\n",
    "                dp[i][j] = 1 + min(dp[i - 1][j], dp[i][j - 1], dp[i - 1][j - 1])\n",
    "\n",
    "    return dp[len_model][len_gt] / len_gt\n",
    "\n",
    "\n",
    "def calculate_bleu(model_output, ground_truth):\n",
    "    smoothie = SmoothingFunction().method1\n",
    "    return sentence_bleu([ground_truth], model_output, smoothing_function=smoothie)\n",
    "\n",
    "\n",
    "def calculate_rouge(model_output, ground_truth, metric=\"rouge-l\"):\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(model_output, ground_truth)\n",
    "    return scores[0][metric][\"f\"]\n",
    "\n",
    "def calcualteMetrics(predictList, ground_truth_list):\n",
    "    em_score = 0\n",
    "    wer_score = 0\n",
    "    bleu_score = 0\n",
    "    rouge_score = 0\n",
    "    for i in range(len(predictList)):\n",
    "        model_output = predictList[i]\n",
    "        ground_truth = ground_truth_list[i]\n",
    "        em_score += calculate_exact_match(model_output, ground_truth)\n",
    "        wer_score += calculate_word_error_rate(model_output, ground_truth)\n",
    "        bleu_score += calculate_bleu(model_output.split(), ground_truth.split())\n",
    "        rouge_score += calculate_rouge(model_output, ground_truth, metric=\"rouge-l\")\n",
    "    \n",
    "    em_score = em_score/len(predictList)*100\n",
    "    wer_score= wer_score/len(predictList)*100\n",
    "    bleu_score = bleu_score/len(predictList)*100\n",
    "    rouge_score = rouge_score/len(predictList)*100\n",
    "    \n",
    "    return em_score, wer_score, bleu_score, rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(em_score, wer_score, bleu_score, rouge_score):\n",
    "\n",
    "    metrics = [\"EM\", \"WER\", \"BLEU\", \"ROUGE\"]\n",
    "    scores = [em_score, wer_score, bleu_score, rouge_score]\n",
    "\n",
    "    plt.bar(metrics, scores)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Evaluation Metrics\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model_output = \"The cat is on the mat\"\n",
    "ground_truth = \"There is a cat on the mat\"\n",
    "\n",
    "#plot_metrics(model_output, ground_truth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_score, wer_score, bleu_score, rouge_score = calcualteMetrics(pred_sentences, real_sentences)\n",
    "plot_metrics(em_score, wer_score, bleu_score, rouge_score)\n",
    "em_score, wer_score, bleu_score, rouge_score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb22b1e55b1fbd8f3cffd3928edc0da66604f23d4dbbba430356986a4eac359a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
